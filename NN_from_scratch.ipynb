{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4672a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ninad\\\\Documents\\\\Data-code\\\\Projects\\\\NN_from_scratch'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d775ab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "   ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "   ---------------------------------------  15.7/15.9 MB 90.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.9/15.9 MB 43.6 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'C:\\Users\\ninad\\anaconda3\\envs\\nn_from_scratch\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "catboost 1.1.1 requires matplotlib, which is not installed.\n",
      "catboost 1.1.1 requires pandas>=0.24.0, which is not installed.\n",
      "catboost 1.1.1 requires scipy, which is not installed.\n",
      "darts 0.23.0 requires holidays>=0.11.1, which is not installed.\n",
      "darts 0.23.0 requires joblib>=0.16.0, which is not installed.\n",
      "darts 0.23.0 requires matplotlib>=3.3.0, which is not installed.\n",
      "darts 0.23.0 requires pandas>=1.0.5, which is not installed.\n",
      "darts 0.23.0 requires prophet>=1.1.1, which is not installed.\n",
      "darts 0.23.0 requires requests>=2.22.0, which is not installed.\n",
      "darts 0.23.0 requires scikit-learn>=1.0.1, which is not installed.\n",
      "darts 0.23.0 requires scipy>=1.3.2, which is not installed.\n",
      "darts 0.23.0 requires statsmodels>=0.13.0, which is not installed.\n",
      "darts 0.23.0 requires torch>=1.8.0, which is not installed.\n",
      "darts 0.23.0 requires tqdm>=4.60.0, which is not installed.\n",
      "lightgbm 3.3.3 requires scikit-learn!=0.22.0, which is not installed.\n",
      "lightgbm 3.3.3 requires scipy, which is not installed.\n",
      "nfoursid 1.0.1 requires matplotlib>=3.3, which is not installed.\n",
      "nfoursid 1.0.1 requires pandas>=1.1, which is not installed.\n",
      "pmdarima 2.0.2 requires Cython!=0.29.18,!=0.29.31,>=0.29, which is not installed.\n",
      "pmdarima 2.0.2 requires joblib>=0.11, which is not installed.\n",
      "pmdarima 2.0.2 requires pandas>=0.19, which is not installed.\n",
      "pmdarima 2.0.2 requires scikit-learn>=0.22, which is not installed.\n",
      "pmdarima 2.0.2 requires scipy>=1.3.2, which is not installed.\n",
      "pmdarima 2.0.2 requires statsmodels>=0.13.2, which is not installed.\n",
      "pmdarima 2.0.2 requires urllib3, which is not installed.\n",
      "pyod 1.0.7 requires joblib, which is not installed.\n",
      "pyod 1.0.7 requires matplotlib, which is not installed.\n",
      "pyod 1.0.7 requires scikit-learn>=0.20.0, which is not installed.\n",
      "pyod 1.0.7 requires scipy>=1.5.1, which is not installed.\n",
      "pyod 1.0.7 requires statsmodels, which is not installed.\n",
      "pytorch-lightning 1.8.6 requires fsspec[http]>2021.06.0, which is not installed.\n",
      "pytorch-lightning 1.8.6 requires PyYAML>=5.4, which is not installed.\n",
      "pytorch-lightning 1.8.6 requires torch>=1.9.0, which is not installed.\n",
      "pytorch-lightning 1.8.6 requires tqdm>=4.57.0, which is not installed.\n",
      "shap 0.41.0 requires cloudpickle, which is not installed.\n",
      "shap 0.41.0 requires pandas, which is not installed.\n",
      "shap 0.41.0 requires scikit-learn, which is not installed.\n",
      "shap 0.41.0 requires scipy, which is not installed.\n",
      "shap 0.41.0 requires tqdm>4.25.0, which is not installed.\n",
      "statsforecast 1.4.0 requires matplotlib, which is not installed.\n",
      "statsforecast 1.4.0 requires pandas>=1.3.5, which is not installed.\n",
      "statsforecast 1.4.0 requires scipy>=1.7.3, which is not installed.\n",
      "statsforecast 1.4.0 requires statsmodels>=0.13.2, which is not installed.\n",
      "statsforecast 1.4.0 requires tqdm, which is not installed.\n",
      "tbats 1.1.2 requires scikit-learn, which is not installed.\n",
      "tbats 1.1.2 requires scipy, which is not installed.\n",
      "tensorboardx 2.5.1 requires protobuf<=3.20.1,>=3.8.0, which is not installed.\n",
      "torchmetrics 0.11.0 requires torch>=1.8.1, which is not installed.\n",
      "xarray 2022.12.0 requires pandas>=1.3, which is not installed.\n",
      "xgboost 1.7.2 requires scipy, which is not installed.\n",
      "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 2.0.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fae3c5",
   "metadata": {},
   "source": [
    "# Creating a Neural Network from scratch with Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3e282",
   "metadata": {},
   "source": [
    "In this project we are going to build a basic neural network from scratch without using libraries like tensorflow or pytorch etc. We want to build an NN with just numpy and understand what is going on behind the scenes when building from the ground up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c8c195",
   "metadata": {},
   "source": [
    "## Define the Neural Network Structure: Initialise the network with input, hidden, and output layer sizes, and set up the initial weights and biases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeed0845",
   "metadata": {},
   "source": [
    "Number of layers: 3\n",
    "1st layer: input layer (L0)\n",
    "2nd layer: hidden layer (L1)\n",
    "3rd layer: output layer (L2)\n",
    "1st layer nodes depend on input data\n",
    "2nd layer will have 10 nodes\n",
    "3rd layer will have same # nodes as input\n",
    "learning rate will be 0.1\n",
    "To go from layer to layer we are using weighted sums and biases.\n",
    "define weights as w0, w1 etc and biases as b0, b1 etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123566b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e642c2df",
   "metadata": {},
   "source": [
    "inital weights and baises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3402a90c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1444692314.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Class NeuralNetwork:\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    def fn:\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec3f37",
   "metadata": {},
   "source": [
    "Define Activation Functions: Implement functions like Sigmoid or ReLU and their derivatives, which introduce non-linearity into the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de9abf",
   "metadata": {},
   "source": [
    "Implement the Forward Pass: Calculate the output of the network by passing input data through each layer, applying weights, biases, and activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9ae78",
   "metadata": {},
   "source": [
    "Define a Loss Function: Choose a metric (e.g., Mean Squared Error) to quantify the difference between the network's predictions and the true outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c171f7a",
   "metadata": {},
   "source": [
    "Implement the Backward Pass (Backpropagation): Calculate the gradients of the loss with respect to each weight and bias in the network, propagating the error backward through the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c298f",
   "metadata": {},
   "source": [
    "Update Weights and Biases: Adjust the network's weights and biases using the calculated gradients and a learning rate to minimize the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2261ce",
   "metadata": {},
   "source": [
    "Create a Training Loop: Iterate through the training data for a specified number of epochs, performing forward passes, backward passes, and weight updates for each sample or batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a1411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN from scratch Env",
   "language": "python",
   "name": "nn_from_scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
